{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b7bbf8",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Data management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdb140",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Why do we have to care about data transfers?\n",
    "\n",
    "The main bottleneck in using GPUs for computing is data transfers between the host and the GPU.\n",
    "\n",
    "Let's have a look at the bandwidths.\n",
    "\n",
    "<img alt=\"Typical bandwidths\" src=\"../../pictures/bandwidths.png\" style=\"float:none\" width=\"40%\"/>\n",
    "\n",
    "On this picture the size of the arrows represents the bandwidth.\n",
    "To have a better idea here are some numbers:\n",
    "\n",
    "- GPU to its internal memory (HBM2): 900 GB/s\n",
    "- GPU to CPU via PCIe: 16 GB/s\n",
    "- GPU to GPU via NVLink: 25 GB/s\n",
    "- CPU to RAM (DDR4): 128 GB/s\n",
    "\n",
    "So if you have to remember only one thing: take care of memory transfers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0541e23f",
   "metadata": {
    "editable": false
   },
   "source": [
    "## The easy way: NVIDIA managed memory\n",
    "\n",
    "NVIDIA offers a feature called [Unified Memory](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/) which allows developers to \"forget\" about data transfers.\n",
    "The memory space of the host and the GPU are shared so that the normal [_page fault_ mechanism](https://en.wikipedia.org/wiki/Page_fault) can be used to manage transfers.\n",
    "\n",
    "This feature is activated with the compiler options:\n",
    "\n",
    "- NVIDIA compilers: `-gpu:managed`\n",
    "- PGI: `-ta=tesla:managed`\n",
    "\n",
    "This might give good performance results and you might just forget explicit data transfers. However, depending on the complexity of your data structures, you might need to deal explicitly with data transfers. The next section gives an introduction to manual data management.\n",
    "\n",
    "Unified Memory also allows to increase virtual memory space on GPU (so called GPU memory oversubscription)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4450501f",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Manual data movement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f73c219",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Data clauses\n",
    "\n",
    "There are multiple data directives that accept the same data clauses. So we start with the data clauses and than continue with data directives.\n",
    "\n",
    "In order to choose the right data clause for data transfers, you need to answer the following two questions:\n",
    "\n",
    "- Does the kernel need the values computed beforehand by the CPU?\n",
    "- Are the values computed inside the kernel needed on the CPU afterhand?\n",
    "\n",
    "|                  | Needed after        | Not needed after  |\n",
    "|------------------|---------------------|-------------------|\n",
    "|Needed before     |  `copy(var1, ...)`    | `copyin(var2, ...)` |\n",
    "|Not needed before |  `copyout(var3, ...)` | `create(var4, ...)` |\n",
    "\n",
    "Figure below illustrates transfers, if any, between the CPU and the GPU for these four clauses.\n",
    "\n",
    "<img alt=\"Data clauses\" src=\"../../pictures/data_clauses_new.png\" style=\"float:none\" width=\"95%\"/>\n",
    "\n",
    "**Important**: the presence of variables on the GPU is checked at runtime. If some variables are already found on the GPU, these clauses have no effect.\n",
    "It means that you cannot update variables (on the GPU at the region entrance or on the CPU at exit).\n",
    "You have to use the `acc update` directive in this case.\n",
    "\n",
    "Other data clauses include:\n",
    "\n",
    "- `present`: check if data is present in the GPU memory; an error is raised if it is not the case\n",
    "- `deviceptr`: pass the GPU pointer; used for interoperability between other APIs (e.g. CUDA, Thrust) and OpenACC\n",
    "- `attach`: attach a pointer to memory already allocated in the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d497abde",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Array shapes and partial data transfers\n",
    "\n",
    "For array transfers, full or partial, one has to follow the language syntax.\n",
    "\n",
    "In C, you have to specify the range of the array in the format `[first index:number of elements]`.\n",
    "\n",
    "```c\n",
    "    #pragma acc data copyout(myarray[0:size])\n",
    "    // In C, 0 is the first index by default and can be omitted\n",
    "    // the previous line is equivalent to\n",
    "    // #pragma acc data copyout(myarray[:size]) \n",
    "    {\n",
    "       // Some really fast kernels\n",
    "    }\n",
    "```\n",
    "For partial data transfer, you can specify a subarray. For example:\n",
    "```c\n",
    "    #pragma acc data copyout(myarray[2:size-2])\n",
    "```\n",
    "\n",
    "Before moving on to data directives, some vocabulary needs to be introduced. According to data lifetime on the GPU, two types of data regions can be distinguished: _structured_ and _unstructured_. Structured data regions are defined within the same scope (e.g. routine), while unstructured data regions allow data creation and deletion in different scopes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7a837",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Implicit structured data regions associated with compute constructs\n",
    "\n",
    "Any of the three compute constructs -- `parallel`, `kernels`, or `serial` -- opens an implicit data region. Data transfers will occur just before the kernel starts and just after the kernel ends.\n",
    "\n",
    "In the [Get started](../Get_started.ipynb) notebook, we have already seen that it is possible to specify data clauses in `acc parallel` to manage our variables.\n",
    "The compiler checks what variables (scalar or arrays) are needed in the kernel and will try to add the _data clauses_ necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb35b1",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "- Create a parallel region for each loop.\n",
    "- For each parallel region, what _data clause_ should be added?\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_vector_sum_exercise.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888418dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "int main(void){\n",
    "    int size = 10000;\n",
    "    int a[size], b[size], c[size];\n",
    "\n",
    "    // Insert OpenACC directive\n",
    "    for(int i=0; i<size; ++i){\n",
    "        a[i] = i;\n",
    "        b[i] = 2*i;\n",
    "    }\n",
    "\n",
    "    // Insert OpenACC directive\n",
    "    for (int i=0; i<size; ++i){\n",
    "        c[i] = a[i]+b[i];\n",
    "    }\n",
    "\n",
    "    printf(\"value at position 14: %d\\n\", c[14]); \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13481202",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Answer\n",
    "\n",
    "- For each parallel region, what _data clause_ should be added?\n",
    "  - Loop 1: The initialization of a and b is done directly on GPU so we don't need to copy the values from CPU.\n",
    "              Variables a and b are used to compute c after execution of the first parallel region.\n",
    "              We need to `copyout` a and b.\n",
    "  - Loop 2: We need the values of a and b to compute c. This computation is the initialization of c.\n",
    "              We print the value of one element of c after execution.\n",
    "              The values of a and b are not needed anymore.\n",
    "              We need to `copyin` a and b. We need to `copyout` c.\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_vector_sum_solution.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56918ce7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%idrrun -a\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "int main(void){\n",
    "    int size = 10000;\n",
    "    int a[size], b[size], c[size];\n",
    "\n",
    "    #pragma acc parallel loop copyout(a, b)\n",
    "    for(int i=0; i<size; ++i){\n",
    "        a[i] = i;\n",
    "        b[i] = 2*i;\n",
    "    }\n",
    "\n",
    "    #pragma acc parallel loop copyin(a, b) copyout(c)\n",
    "    for (int i=0; i<size; ++i){\n",
    "        c[i] = a[i]+b[i];\n",
    "    }\n",
    "\n",
    "    printf(\"value at position 14: %d\\n\", c[14]); \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912c747",
   "metadata": {},
   "source": [
    "If you use NVIDIA compilers (formerly PGI), most of the time the right directives will be added _implicitly_.\n",
    "\n",
    "Our advice is to make explicit all actions performed implicitly by the compiler.\n",
    "It will help you to keep a code understandable and avoid porting problems if you have to change compiler.\n",
    "\n",
    "All compilers might not choose the same default behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b99c6b",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Explicit structured data regions `acc data`\n",
    "\n",
    "Using the _data regions_ associated to kernels is quite convenient and is a good strategy for incremental porting of your code.\n",
    "\n",
    "However, this results in a large number of data transfers that can be avoided.\n",
    "\n",
    "If we take a look at the previous example, we count 5 data transfers:\n",
    "\n",
    "- Loop 1: copyout(a, b)\n",
    "- Loop 2: copyin(a, b) copyout(c)\n",
    "\n",
    "If we look closely we can see that we do not need a and b on the CPU between the kernels.\n",
    "It means that data transfers of a and b at the end of kernel1 and at the beginning of kernel2 are useless.\n",
    "\n",
    "The solution is to encapsulate the two loops in a _structured data region_ that you can open we the directive `acc data`.\n",
    "The syntax is:\n",
    "\n",
    "```c\n",
    "#pragma acc data <data clauses>\n",
    "{\n",
    "    // Your code\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585cdd2",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "Analyze the code to create a _structured data region_ that encompasses both loops.\n",
    "The data clause `present` have been added to the _data region associated with kernels_. You should not remove this part.\n",
    "\n",
    "How many data transfers occurred?\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_structured_data_region_exercise.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun -a\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "int main(void){\n",
    "    int size = 10000;\n",
    "    int a[size], b[size], c[size];\n",
    "\n",
    "    {\n",
    "        #pragma acc parallel loop present(a, b)\n",
    "        for(int i=0; i<size; ++i){\n",
    "            a[i] = i;\n",
    "            b[i] = 2*i;\n",
    "        }\n",
    "\n",
    "        #pragma acc parallel loop present(a, b, c)\n",
    "        for (int i=0; i<size; ++i){\n",
    "            c[i] = a[i]+b[i];\n",
    "        }\n",
    "    }\n",
    "    printf(\"value at position 14: %d\\n\", c[14]); \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed666a9",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Solution\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_structured_data_region_solution.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee5d16",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%idrrun -a\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "int main(void)\n",
    "{\n",
    "    int size = 10000;\n",
    "    int a[size], b[size], c[size];\n",
    "\n",
    "// Structured data region\n",
    "    #pragma acc data create(a, b) copyout(c)\n",
    "    {\n",
    "        #pragma acc parallel loop present(a, b)\n",
    "        for(int i=0; i<size; ++i){\n",
    "            a[i] = i;\n",
    "            b[i] = 2*i;\n",
    "        }\n",
    "\n",
    "        #pragma acc parallel loop present(a, b, c)\n",
    "        for (int i=0; i<size; ++i){\n",
    "            c[i] = a[i]+b[i];\n",
    "        }\n",
    "    } // End of structured data region\n",
    "    printf(\"value at position 14: %d\\n\", c[14]); \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67328b2",
   "metadata": {},
   "source": [
    "When using _structured data region_ we advise to use the `present` data clause which tells that the data should already be in GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4658baf7",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### WRONG example\n",
    "\n",
    "Here we are going to simulate a case where we make modifications on the CPU between 2 GPU kernels.\n",
    "This can happen when you are in the porting phase or because some parts of the computation cannot be executed on the GPU.\n",
    "\n",
    "The example given below doesn't give the right results on the CPU. Why?\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_wrong_example.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a2ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun -a\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "int main(void){\n",
    "    int size = 10000;\n",
    "    int a[size], b[size], c[size];\n",
    "\n",
    "// Structured data region\n",
    "    #pragma acc data create(a, b) copyout(c)\n",
    "    {\n",
    "        #pragma acc parallel loop present(a, b)\n",
    "        for(int i=0; i<size; ++i){\n",
    "            a[i] = i;\n",
    "            b[i] = 2*i;\n",
    "        }\n",
    "        // We update an element of the array on the CPU \n",
    "        a[14] = 78324;\n",
    "\n",
    "        #pragma acc parallel loop present(b, c) copyin(a)\n",
    "        for (int i=0; i<size; ++i){\n",
    "            c[i] = a[i]+b[i];\n",
    "        }\n",
    "    }\n",
    "    printf(\"value at position 14: %d\\n\", c[14]); \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07da19",
   "metadata": {},
   "source": [
    "This example is here to emphasize that you cannot update data with data clauses.\n",
    "It has an unintended behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0484367",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Updating data\n",
    "\n",
    "Let's say that all your code is not ported to the GPU.\n",
    "Then it means that you will have some variables (arrays or scalars) for which both, the CPU and the GPU, will perform computation.\n",
    "\n",
    "To keep the results correct, you will have to update those variables when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3677e7db",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### `acc update device`\n",
    "\n",
    "To update the value a variable has on the GPU with what the CPU has you have to use:\n",
    "```c\n",
    "#pragma acc update device(var1, var2, ...)\n",
    "```\n",
    "\n",
    "**Important**: The directive cannot be used inside a compute construct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb580cd",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### `acc update self`\n",
    "\n",
    "Once again if all your code is not ported on GPU the values computed on the GPU may be needed afterwards on the CPU.\n",
    "\n",
    "The directive to use is:\n",
    "```c\n",
    "#pragma acc update self(var1, var2, ...)\n",
    "```\n",
    "\n",
    "Correct the previous example in order to obtain correct restuls:\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_wrong_example.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun -a\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "int main(void){\n",
    "    int size = 10000;\n",
    "    int a[size], b[size], c[size];\n",
    "\n",
    "// Structured data region\n",
    "    #pragma acc data create(a, b) copyout(c)\n",
    "    {\n",
    "        #pragma acc parallel loop present(a, b)\n",
    "        for(int i=0; i<size; ++i){\n",
    "            a[i] = i;\n",
    "            b[i] = 2*i;\n",
    "        }\n",
    "        // We update an element of the array on the CPU \n",
    "        a[14] = 78324;\n",
    "\n",
    "        #pragma acc parallel loop present(b, c) copyin(a)\n",
    "        for (int i=0; i<size; ++i){\n",
    "            c[i] = a[i]+b[i];\n",
    "        }\n",
    "    }\n",
    "    printf(\"value at position 14: %d\\n\", c[14]); \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f933ee21",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Explicit unstructured data regions `acc enter data`\n",
    "\n",
    "Each time you run a code on the GPU, a data region is created for the lifetime of the program.\n",
    "\n",
    "There are two directives to manage data inside this region:\n",
    "\n",
    "- `acc enter data <input data clause>`: to put data inside the region (allocate memory, copy data from the CPU to the GPU)\n",
    "- `acc exit data <output data clause>`: to remove data (deallocate memory, copy data from the GPU to the CPU)\n",
    "\n",
    "This feature is helpful when you have your variables declared at one point of your code and used in another one (modular programming).\n",
    "You can allocate memory as soon as the variable is created and just use _present_ when you create kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b6e2f3",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### `acc enter data`\n",
    "\n",
    "This directive is used to put data on the GPU inside the unstructured data region spanning the lifetime of the program.\n",
    "It will allocate the memory necessary for the variables and, if asked, copy the data present on the CPU to the GPU.\n",
    "\n",
    "It accepts the clauses:\n",
    "\n",
    "- _create_: allocate memory on the GPU\n",
    "- _copyin_: allocate memory on the GPU and initialize it with the values that the variable has on the CPU\n",
    "- _attach_: attach a pointer to memory already in the GPU\n",
    "\n",
    "The most common clauses are _create_ and _copyin_. The _attach_ clause is a bit more advanced and is not covered in this part.\n",
    "\n",
    "Here is an example of syntax:\n",
    "```c\n",
    "#pragma acc enter data copyin(var1[:size_var1], ...) create(var2[0:size_var2])\n",
    "```\n",
    "\n",
    "\n",
    "**Important:** the directive must appear after the allocation of the memory on the CPU.\n",
    "\n",
    "```c\n",
    "double* var = (double*) malloc(size_var*sizeof(double));\n",
    "#pragma acc enter data create(var[0:size_var])\n",
    "```\n",
    "\n",
    "\n",
    "Otherwise you will have a runtime error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfcdebf",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### `acc exit data`\n",
    "\n",
    "By default, the memory allocated with `acc enter data` is freed at the end of the program.\n",
    "But usually you do not have access to very large memory on the GPU (it depends on the card but usually you have access to a few tens of GB)\n",
    "and it might be necessary to have a fine control on what is present.\n",
    "\n",
    "The directive `acc exit data <output data clause>` is used to remove data from the GPU.\n",
    "It accepts the clauses:\n",
    "\n",
    "- _copyout_: copy to the CPU the values that the variable have on the GPU\n",
    "- _delete_: free the memory on the GPU\n",
    "- _detach_: remove the attachment of the pointer to the memory\n",
    "\n",
    "**Important:** the directive must appear before memory deallocation on the CPU.\n",
    "\n",
    "```c\n",
    "#pragma acc exit data delete(var[0:size_var])\n",
    "free(var);\n",
    "```\n",
    "\n",
    "Otherwise you will have a runtime error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab45ca6",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "In this exercise you have to add data management directives in order to:\n",
    "\n",
    "- allocate memory on the GPU for `array`\n",
    "- perform the initialization on the GPU\n",
    "- free the memory on the GPU.\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_unstructured_exercise.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27228846",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun -a\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "double* init(size_t size){\n",
    "    double* array = (double*) malloc(size*sizeof(double));\n",
    "    return array;\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "    size_t size = 100000;\n",
    "    double* array = init(size);\n",
    "    for (size_t i=0; i<size; ++i)\n",
    "        array[i] = (double)i;\n",
    "    printf(\"This should be 42: %f\\n\", array[42]);\n",
    "    free(array);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e396b0b",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Solution\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_unstructured_solution.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12707d54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%idrrun -a\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "double* init(size_t size){\n",
    "    double* array = (double*) malloc(size*sizeof(double));\n",
    "    #pragma acc enter data create(array[0:size])\n",
    "    return array;\n",
    "}\n",
    "\n",
    "int main(void){\n",
    "    size_t size = 100000;\n",
    "    double* array = init(size);\n",
    "    #pragma acc parallel loop present(array[0:size])\n",
    "    for (size_t i=0; i<size; ++i)\n",
    "        array[i] = i;\n",
    "    printf(\"%f\\n\", array[42]);\n",
    "    #pragma acc exit data delete(array[0:size])\n",
    "    free(array);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d9fdf9",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Implicit data regions `acc declare`\n",
    "\n",
    "An implicit data region is created for a program and each subprogram. You can manage data inside these data regions using `acc declare` directive.\n",
    "\n",
    "An implicit data region is created for each function you write.\n",
    "You can manage data inside it with the `acc declare` directive.\n",
    "\n",
    "\n",
    "```c\n",
    "int size = 1000000;\n",
    "double* array;\n",
    "#pragma acc declare create(array[0:size])\n",
    "```\n",
    "\n",
    "In Fortran this directive can also be used for variables declared inside modules.\n",
    "\n",
    "In addition to regular data causes, it accepts `device_resident` cause for variables needed only on the GPU.\n",
    "\n",
    "Example given below illustrates usage of this clause."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe20cb8",
   "metadata": {
    "editable": false
   },
   "source": [
    "##### Example\n",
    "\n",
    "In this example we normalize rows (C) or columns (Fortran) of a square matrix.\n",
    "The algorithm uses a temporary array (norms) which is only used on the GPU.\n",
    "\n",
    "Example stored in: `../../examples/C/Data_Management_unstructured_declare_example.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd57ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun -a\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "void normalize_rows(double* mat, size_t size)\n",
    "{\n",
    "    double norms[size];\n",
    "    #pragma acc declare device_resident(norms)\n",
    "    double norm;\n",
    "    // Compute the L1 norm of each row\n",
    "    #pragma acc parallel loop present(mat[0:size*size])\n",
    "    for (size_t i=0; i<size; ++i)\n",
    "    {\n",
    "        norm = 0.;\n",
    "        #pragma acc loop reduction(+:norm)\n",
    "        for (size_t j=0; j<size; ++j)\n",
    "            norm += mat[i*size+j];\n",
    "        norms[i] = norm;\n",
    "    }\n",
    "    // Divide each row element by the L1 norm \n",
    "    #pragma acc parallel loop present(mat[0:size*size])\n",
    "    for (size_t i=0; i<size; ++i)\n",
    "        for (size_t j=0; j<size; ++j)\n",
    "            mat[i*size+j] /= norms[i];\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    size_t size = 2000;\n",
    "    double* mat = malloc(size*size*sizeof(double));\n",
    "    double sum = 0.;\n",
    "    srand((unsigned) 12345900);\n",
    "    for (size_t i=0; i<size; ++i)\n",
    "        for (size_t j=0; j<size; ++j)\n",
    "            mat[i*size+j] = (double)rand() / (double) RAND_MAX;\n",
    "    #pragma acc enter data copyin(mat[0:size*size])\n",
    "\n",
    "    normalize_rows(mat, size);\n",
    "\n",
    "    // Compute the sum of all elements in the matrix\n",
    "    #pragma acc parallel loop present(mat[0:size*size]) reduction(+:sum)\n",
    "    for (size_t i=0; i<size; ++i)\n",
    "        for (size_t j=0; j<size; ++j)\n",
    "            sum += mat[i*size+j];\n",
    "    #pragma acc exit data delete(mat[0:size*size])\n",
    "    free(mat);\n",
    "\n",
    "    printf(\"%f == %d?\\n\", sum, size);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU Directives",
   "language": "python",
   "name": "gpu_directives"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
