{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee4bf21",
   "metadata": {
    "editable": false
   },
   "source": [
    "# OpenMP offloading directives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059fab5",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Directives\n",
    "\n",
    "OpenMP since specification 4.5 includes support for offloading to accelerators like GPUs.\n",
    "It uses directives to do so (just like for CPU).\n",
    "\n",
    "A directive has the following structure:\n",
    "\n",
    "<img src=\"../../pictures/directive_omp.png\" style=\"float:none\" width=\"30%\"/>\n",
    "\n",
    "If we break it down, we have these elements:\n",
    "\n",
    "- The sentinel is special instruction for the compiler. It tells it that what follows has to be interpreted as OpenACC\n",
    "- The directive is the action to do. In the example, _target_ is the way to open a region that will be offloaded to the GPU\n",
    "- The clauses are \"options\" of the directive. In the example we want to copy some data on the GPU.\n",
    "- The clause arguments give more details for the clause. In the example, we give the name of the variables to be copied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21561ee2",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Compiling with NVIDIA compiler\n",
    "\n",
    "To enable OpenMP GPU offloading you need to activate the compilation options `-mp=gpu -gpu=<gpu,opts>`.\n",
    "For example to compile for NVIDIA V100:\n",
    "\n",
    "```bash\n",
    "nvfortran -mp=gpu -gpu=cc70 -o test test.f90\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb746c94",
   "metadata": {
    "editable": false
   },
   "source": [
    "## GPU offloading\n",
    "\n",
    "With OpenMP the offloading is realized with the `omp target` directive.\n",
    "By itself, the directive will only offload the computation and do not activate parallelism.\n",
    "It is similar to the `acc serial` compute construct in OpenACC since only one GPU thread is running.\n",
    "\n",
    "With OpenMP the developer has to activate manually the parallelism.\n",
    "\n",
    "Here is an example on how to create a GPU kernel:\n",
    "```fortran\n",
    "!$omp target\n",
    "...\n",
    "!$omp end target\n",
    "```\n",
    "\n",
    "Now that we run on the GPU we have to create the threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc805de",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Thread creation on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f182195",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Teams\n",
    "\n",
    "OpenMP `target teams` directive creates several groups of threads that will be able to work in parallel.\n",
    "\n",
    "<span style=\"font-size: .8rem\"> With OpenACC it would correspond to the `gang` level of parallelism.</span>\n",
    "\n",
    "```fortran\n",
    "!$omp target teams\n",
    "...\n",
    "!$omp end target\n",
    "```\n",
    "\n",
    "By default the teams will work in replicated mode meaning that they will perform exactly the same things.\n",
    "If you want to share the iterations of a loop between the threads of the teams you have to use the `teams distribute` directive.\n",
    "\n",
    "```fortran\n",
    "!$omp target\n",
    "    !$omp teams distribute\n",
    "    do i=0, sys_size\n",
    "        ...\n",
    "    enddo\n",
    "!$omp end target\n",
    "```\n",
    "\n",
    "This will split the iterations of the loop among the teams. Each team will have a contiguous set of iterations.\n",
    "\n",
    "It starting to be interesting but we do not yet take advantage of the full power of the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3ce81",
   "metadata": {
    "editable": false
   },
   "source": [
    "### More threads with `omp parallel`\n",
    "\n",
    "With the `omp parallel` directive inside a `omp teams` region we create the threads that will be used inside the team.\n",
    "\n",
    "```fortran\n",
    "!$omp target teams distribute parallel\n",
    "do i=1, sys_size\n",
    "    ...\n",
    "enddo\n",
    "```\n",
    "\n",
    "In this case the threads generated inside the teams will work in replicated mode.\n",
    "If we want to further split the work among those threads we have to add the `omp do` (Fortran) or `omp for` (C/C++) directive.\n",
    "\n",
    "```fortran\n",
    "!$omp target teams distribute parallel do\n",
    "do i=1, sys_size\n",
    "    ...\n",
    "enddo\n",
    "```\n",
    "\n",
    "\n",
    "<span style=\"font-size: .8rem\"> With OpenACC it would correspond to the `worker` level of parallelism.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba948d",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Let's vectorize with `omp simd`\n",
    "\n",
    "The last level of parallelism we can leverage with OpenMP is the SIMD vectorization.\n",
    "It is done with the `omp simd` directive:\n",
    "\n",
    "```fortran\n",
    "!$omp target teams distribute parallel do simd\n",
    "do i=1, sys_size\n",
    "    ...\n",
    "enddo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a6995",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Note for NVIDIA compilers\n",
    "\n",
    "The `omp simd` construct is not supported for GPU. Currently, the `parallel` directive creates the threads that should be created with `simd`.\n",
    "Since the directive is just ignored, we recommend that you write it for portability reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ab802",
   "metadata": {
    "editable": false
   },
   "source": [
    "### `collapse` clause\n",
    "\n",
    "The  `collapse` clause enables to merge all the iterations of several associated loops into a single large iteration loop. The number of loops that will be merged is indicated as an integer argument to this clause and should be greater than 1.\n",
    "\n",
    "```fortran\n",
    "!$omp target teams distribute parallel do simd collapse(3)\n",
    "do k = 1, nz\n",
    "    do j = 1, ny\n",
    "        do i = 1, nx\n",
    "            ...\n",
    "        enddo\n",
    "    enddo\n",
    "enddo\n",
    "```\n",
    "\n",
    "Up to now, we will recommend you to use the collapse clause as much as you can with OpenMP target in order to achieve good performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e5a18",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Example\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_basic_offloading.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb177552",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun --options \"-mp=gpu -gpu=cc70 -Minfo=all\"\n",
    "program basic_offloading\n",
    "    use iso_fortran_env, only : real64\n",
    "    implicit none    \n",
    "    \n",
    "    integer                                      :: i, sys_size\n",
    "    real(kind=real64), allocatable, dimension(:) :: array\n",
    "\n",
    "    sys_size = 100000000\n",
    "\n",
    "    allocate(array(sys_size))\n",
    "\n",
    "    !$omp target teams distribute parallel do simd\n",
    "    do i=1, sys_size\n",
    "        array(i) = real(i)\n",
    "    enddo\n",
    "    \n",
    "    print *, \"array(42) = \", array(42)\n",
    "end program basic_offloading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4a2f8b",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Reductions\n",
    "\n",
    "Reductions should be performed when a memory location is updated by several threads concurrently, and usually prior to its previous value.\n",
    "\n",
    "This can be performed by using the `reduction` clause of the target construct. This clause will create a private copy of the variables and initialize them as a function of the requested reduction operation. Once you reach the end of the kernel, the original variable will be updated with a combination of all the private copies.\n",
    "\n",
    "The syntax is:\n",
    "\n",
    "```fortran\n",
    "!$omp target parallel do reduction(operation:variable_list)\n",
    "    ...\n",
    "```\n",
    "\n",
    "The available operations are:\n",
    "\n",
    "- +, -\n",
    "- \\*\n",
    "- &, |, ^, &&, ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c5b9f9",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Limitation\n",
    "\n",
    "The reductions are now only supported for the 2 following combined constructs:\n",
    "\n",
    "- `omp target parallel for`\n",
    "- `omp target teams distribute parallel for`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081ca8d",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Data management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d38c5",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Implicit behavior\n",
    "\n",
    "If not specified in a `data map` structure, variables will be mapped implicitly at the entry of one kernel with a default action depending on the type of the variable.\n",
    "\n",
    "Scalars will be map as `firstprivate`, i.e. every thread will have its own private copy that will be initialized with the value that the scalar have on the CPU before the kernel.\n",
    "\n",
    "Arrays will be shared in memory between threads and are implicitly mapped as if you specified `map(tofrom:)`.\n",
    "\n",
    "Pointers will be private by default.\n",
    "\n",
    "You can see the effect of this implicit behavior with the example below:\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_Implicit_behavior.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun --options \"-mp=gpu -gpu=cc70 -Minfo=all\"\n",
    "program Implicit_behavior\n",
    "    use iso_fortran_env, only : INT32, REAL64\n",
    "    implicit none    \n",
    "    \n",
    "    real   (kind=REAL64), dimension(:)  , allocatable :: Array\n",
    "    integer(kind=INT32 )                              :: nx, i, scalar\n",
    "\n",
    "    nx = 10\n",
    "    allocate(Array(nx))\n",
    "\n",
    "    scalar = 1000\n",
    "    !$omp target teams distribute parallel do simd\n",
    "    do i = 1, nx\n",
    "        Array(i) = scalar + i\n",
    "    enddo\n",
    "\n",
    "    print *, Array\n",
    "\n",
    "    scalar = -1000\n",
    "    !$omp target teams distribute parallel do simd\n",
    "    do i = 1, nx\n",
    "        Array(i) = scalar + i\n",
    "    enddo\n",
    "\n",
    "    print *, Array\n",
    "\n",
    "    deallocate(Array)\n",
    "end program Implicit_behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb25384",
   "metadata": {},
   "source": [
    "Relying only on the implicit behavior can lead to performance degradation as data transfers are performed back and forth at every kernels. This should be avoid by using data regions.\n",
    "\n",
    "You can define a specific action to perform at the entry and/or the exit of a kernel for a variable or a set of variable with the `map` clause of the `target` construct.\n",
    "\n",
    "The available options are:\n",
    "\n",
    "- `alloc` to create the memory space of the variables without prior data transfer.\n",
    "- `to` to create the memory space of the variables and transfer the values from CPU to GPU at the entry of the kernel.\n",
    "- `from` to create the memory space of the variables and transfer the values from GPU to CPU at the exit of the kernel.\n",
    "- `tofrom` to create the memory space of the variables and transfer the values from CPU to GPU at the entry of the kernel, then from GPU to CPU at the exit.\n",
    "\n",
    "<img src=\"../../pictures/data_clauses_omp.png\" style=\"float:none\" width=\"65%/\"/>\n",
    "\n",
    "The syntax is:\n",
    "\n",
    "```fortran\n",
    "!$omp target map(to:variable1, variable2)\n",
    "    ...\n",
    "!$omp end target\n",
    "```\n",
    "\n",
    "It is also possible to modify the status of the variable manually with the `private` and `firstprivate` clauses of the `target` construct or by setting a default mapping that we will see later.\n",
    "\n",
    "```fortran\n",
    "!$omp target private(variable1,variable2) firstprivate(variable3)\n",
    "    ...\n",
    "    ! variable1 and variable2 will have independent memory allocations for each threads\n",
    "    ! variable2 will have independent memory allocations for each threads and will be initialized with the CPU value\n",
    "!$omp end target\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde8406",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Structured data region\n",
    "\n",
    "To run the kernels on GPU, the data should be allocated on the device and eventually the original values should be transfered from the CPU to the GPU.\n",
    "You will also have to retrieve some of the data back from the GPU to the CPU in order to store your results.\n",
    "This can be perfomed withing the same program unit by using the `target data` construct.\n",
    "\n",
    "If you don't use data regions, implicit copies of the variables will be performed at each entry and exit of every kernels.\n",
    "This implies transfers trough the PCIe that could be avoided and thus non-optimal performances.\n",
    "\n",
    "This construct map the variable to the device, but only for the extent of the region.\n",
    "The `map` clause enables you to decide which action will be performed on the gpu.\n",
    "These actions could be `alloc`, `to`, `from`, `tofrom`.\n",
    "\n",
    "You can retrieve the values that were stored on the GPU with `from` and `tofrom` clauses\n",
    "\n",
    "You can inform the GPU of the original CPU values with the clauses `to` and `tofrom`.\n",
    "\n",
    "If you use the `alloc` or `from` clause, the initial value on the device is undetermined.\n",
    "\n",
    "The syntax is:\n",
    "\n",
    "```fortran\n",
    "real :: A(nx,ny), B(nx,ny)\n",
    "\n",
    "!$omp target data map(tofrom:A,B)\n",
    "    ...\n",
    "!$omp end target data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5111417",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Persistent data (`enter data` / `exit data`)\n",
    "\n",
    "If you want to allocate the memory of some variables on the device at a given point of your program but it is not possible to free the memory within the same scope of the program,\n",
    "you can then use the `enter data` and `exit data` constructs.\n",
    "\n",
    "`enter data` will enable you to allocate or allocate and initialize the variables on the GPU with the `map(alloc:variable_list)` and `map(to:variable_list)` clauses respectively.\n",
    "\n",
    "`exit data` will enable you to free the memory from the device, resp. free the memory after retrieving the data, with the `map(delete:variable_list)`, resp. `map(from:variable_list)`.\n",
    "\n",
    "These 2 constructs are not tied to each other, such as one `enter data` construct mapping several variables can lead to several `exit data` constructs in different portions of the code as long as 2 `exit data` are not refering to the same variable in this example.\n",
    "\n",
    "The syntax is:\n",
    "\n",
    "```fortran\n",
    "subroutine some_function_somewhere()\n",
    "    real :: A(nx,ny), B(nx,ny)\n",
    "\n",
    "    !$omp target enter data map(to:A)\n",
    "    !$omp target enter data map(alloc:B)\n",
    "    ...\n",
    "end subroutine some_function_somewhere\n",
    "\n",
    "subroutine some_function_elsewhere_or_maybe_the_same_as_before()\n",
    "    ...\n",
    "    !$omp target exit data map(delete:A,B)\n",
    "end subroutine some_function_elsewhere_or_maybe_the_same_as_before\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b84bd0",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Manual data tranfers\n",
    "\n",
    "When you want to update the values of a given variable, or a set of variables, either on the GPU or on the CPU, you can use the `target update` construct in order to avoid doing it by closing a data structure.\n",
    "\n",
    "The `to` clause will update the GPU.\n",
    "\n",
    "The `from` clause will update the CPU.\n",
    "\n",
    "```fortran\n",
    "!$omp target update to(variable1,variable2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f6b84",
   "metadata": {
    "editable": false
   },
   "source": [
    "### `defaultmap` clause\n",
    "\n",
    "You can modify the default mapping for the data transfer upon kernels or data structures with the `defaultmap` clause of the `target` and `target data` constructs.\n",
    "\n",
    "The new implicit behavior can be specified as `alloc`, `to`, `from`, `tofrom`, `default`, `none`, `firstprivate` or `present` and should be applied to a variable category. Variable categories are:\n",
    "\n",
    "- scalar\n",
    "- aggregate (corresponding to arrays and structures in C/C++ and to derived types in Fortran)\n",
    "- allocatable (only for Fortran arrays that are dynamically allocated)\n",
    "- pointers\n",
    "\n",
    "If you specify the implicit behavior as `none`, you should then map explicitly all variables.\n",
    "\n",
    "```fortran\n",
    "real, dimension(:), allocatable :: A\n",
    "real                            :: B\n",
    "!$omp target data defaultmap(firstprivate:scalar) defaultmap(tofrom:allocatable)\n",
    "   ...\n",
    "!$omp end target data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc27322",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Modular programming\n",
    "\n",
    "Functions that are call inside a kernel should be executed on the accelerator. You should use the `declare target` construt to inform the compiler that it should produce such an executable. Syntax should be:\n",
    "\n",
    "```fortran\n",
    "subroutine my_routine(...)\n",
    "!$omp declare target\n",
    "        ...\n",
    "end subroutine my_routine\n",
    "```\n",
    "\n",
    "\n",
    "If the function and the line from which the function is called are not within the same program unit, you should add a named `declare target` construct within the program unit containing the call.\n",
    "\n",
    "```fortran\n",
    "subroutine another_routine\n",
    "!$omp declare target(my_routine)\n",
    "\n",
    "!$omp target teams\n",
    "call my_routine()\n",
    "!$omp end target teams\n",
    "\n",
    "end subroutine another_routine\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c0bca",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_Modular_programming_mean_value_exercise.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae87e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun --options \"-mp=gpu -gpu=cc70 -Minfo=all\"\n",
    "module calcul\n",
    "    use iso_fortran_env, only : INT32, REAL64\n",
    "    contains\n",
    "        subroutine rand_init(array,n)\n",
    "            real   (kind=REAL64), dimension(1,n), intent(inout) :: array\n",
    "            integer(kind=INT32 ), intent(in)                    :: n\n",
    "            real   (kind=REAL64)                                :: rand_val\n",
    "            integer(kind=INT32)                                 :: i\n",
    "\n",
    "            call srand(12345900)\n",
    "            do i = 1, n\n",
    "               call random_number(rand_val)\n",
    "               array(1,i) = 2.0_real64*(rand_val-0.5_real64)\n",
    "            enddo\n",
    "        end subroutine rand_init\n",
    "\n",
    "        subroutine iterate(array, array_size, cell_size)\n",
    "            real   (kind=REAL64), dimension(1:array_size,1), intent(inout) :: array\n",
    "            integer(kind=INT32 ), intent(in)                               :: array_size, cell_size\n",
    "            real   (kind=REAL64)                                           :: local_mean\n",
    "            integer(kind=INT32 )                                           :: i\n",
    " \n",
    "            \n",
    "            do i = cell_size/2, array_size-cell_size/2\n",
    "                local_mean = mean_value(array(i+1-cell_size/2:i+cell_size/2,1), cell_size)\n",
    "                if (local_mean .lt. 0.0_real64) then\n",
    "                    array(i,1) = array(i,1) + 0.1\n",
    "                else\n",
    "                    array(i,1) = array(i,1) - 0.1\n",
    "                endif\n",
    "            enddo\n",
    "        end subroutine iterate\n",
    "\n",
    "        function mean_value(t, n)\n",
    "            real   (kind=REAL64), dimension(n,1), intent(inout) :: t\n",
    "            integer(kind=INT32 ), intent(in)                    :: n\n",
    "            real   (kind=REAL64)                                :: mean_value\n",
    "            integer(kind=INT32 )                                :: i\n",
    "            mean_value = 0.0_real64\n",
    "            \n",
    "            do i = 1, n\n",
    "                mean_value = mean_value + t(i,1)\n",
    "            enddo\n",
    "            mean_value = mean_value / dble(n)\n",
    "        end function mean_value\n",
    "end module calcul\n",
    "program modular_programming\n",
    "    use calcul\n",
    "    implicit none    \n",
    "    \n",
    "    real   (kind=REAL64), dimension(:,:), allocatable :: table\n",
    "    real   (kind=REAL64), dimension(:)  , allocatable :: mean_values\n",
    "    integer(kind=INT32 )                              :: nx, ny, cell_size, i\n",
    "\n",
    "    nx =   10000\n",
    "    ny =    3000\n",
    "    allocate(table(nx,ny), mean_values(ny))\n",
    "    table(:,:) = 0.0_real64\n",
    "    call rand_init(table(1,:),ny)\n",
    "    cell_size = 32\n",
    "    do i = 2, ny   \n",
    "        call iterate(table(:,i), nx, cell_size)\n",
    "    enddo\n",
    "\n",
    "    do i = 1, ny\n",
    "        mean_values(i) = mean_value(table(:,i), nx)\n",
    "    enddo\n",
    "\n",
    "    do i = 1, 10\n",
    "        write(0,\"(a18,i5,a1,f20.8)\") \"Mean value of row \",i,\"=\",mean_values(i)\n",
    "    enddo\n",
    "\n",
    "    do i = ny-10, ny\n",
    "        write(0,\"(a18,i5,a1,f20.8)\") \"Mean value of row \",i,\"=\",mean_values(i)\n",
    "    enddo    \n",
    "    \n",
    "    deallocate(table, mean_values)\n",
    "end program modular_programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe9a6e7",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Solution\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_Modular_programming_mean_value_solution.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca26a1df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%idrrun --options \"-mp=gpu -gpu=cc70 -Minfo=all\"\n",
    "module calcul\n",
    "    use iso_fortran_env, only : INT32, REAL64\n",
    "    contains\n",
    "        subroutine rand_init(array,n)\n",
    "            real   (kind=REAL64), dimension(1,n), intent(inout) :: array\n",
    "            integer(kind=INT32 ), intent(in)                    :: n\n",
    "            real   (kind=REAL64)                                :: rand_val\n",
    "            integer(kind=INT32)                                 :: i\n",
    "\n",
    "            call srand(12345900)\n",
    "            do i = 1, n\n",
    "               call random_number(rand_val)\n",
    "               array(1,i) = 2.0_real64*(rand_val-0.5_real64)\n",
    "            enddo\n",
    "        end subroutine rand_init\n",
    "\n",
    "        subroutine iterate(array, array_size, cell_size)\n",
    "        !$omp declare target\n",
    "            real   (kind=REAL64), dimension(1:array_size,1), intent(inout) :: array\n",
    "            integer(kind=INT32 ), intent(in)                               :: array_size, cell_size\n",
    "            real   (kind=REAL64)                                           :: local_mean\n",
    "            integer(kind=INT32 )                                           :: i\n",
    " \n",
    "            \n",
    "            do i = cell_size/2, array_size-cell_size/2\n",
    "                local_mean = mean_value(array(i+1-cell_size/2:i+cell_size/2,1), cell_size)\n",
    "                if (local_mean .lt. 0.0_real64) then\n",
    "                    array(i,1) = array(i,1) + 0.1\n",
    "                else\n",
    "                    array(i,1) = array(i,1) - 0.1\n",
    "                endif\n",
    "            enddo\n",
    "        end subroutine iterate\n",
    "\n",
    "        function mean_value(t, n)\n",
    "        !$omp declare target\n",
    "            real   (kind=REAL64), dimension(n,1), intent(inout) :: t\n",
    "            integer(kind=INT32 ), intent(in)                    :: n\n",
    "            real   (kind=REAL64)                                :: mean_value\n",
    "            integer(kind=INT32 )                                :: i\n",
    "            mean_value = 0.0_real64\n",
    "            \n",
    "            do i = 1, n\n",
    "                mean_value = mean_value + t(i,1)\n",
    "            enddo\n",
    "            mean_value = mean_value / dble(n)\n",
    "        end function mean_value\n",
    "end module calcul\n",
    "program modular_programming\n",
    "    use calcul\n",
    "    implicit none    \n",
    "    \n",
    "    real   (kind=REAL64), dimension(:,:), allocatable :: table\n",
    "    real   (kind=REAL64), dimension(:)  , allocatable :: mean_values\n",
    "    integer(kind=INT32 )                              :: nx, ny, cell_size, i\n",
    "\n",
    "    nx =   10000\n",
    "    ny =    3000\n",
    "    allocate(table(nx,ny), mean_values(ny))\n",
    "    table(:,:) = 0.0_real64\n",
    "    call rand_init(table(1,:),ny)\n",
    "    !$omp target enter data map(to:table)\n",
    "    cell_size = 32\n",
    "    !$omp target teams distribute parallel do simd\n",
    "    do i = 2, ny   \n",
    "        call iterate(table(:,i), nx, cell_size)\n",
    "    enddo\n",
    "\n",
    "    !$omp target teams distribute parallel do simd map(from:mean_values)\n",
    "    do i = 1, ny\n",
    "        mean_values(i) = mean_value(table(:,i), nx)\n",
    "    enddo\n",
    "\n",
    "    do i = 1, 10\n",
    "        write(0,\"(a18,i5,a1,f20.8)\") \"Mean value of row \",i,\"=\",mean_values(i)\n",
    "    enddo\n",
    "\n",
    "    do i = ny-10, ny\n",
    "        write(0,\"(a18,i5,a1,f20.8)\") \"Mean value of row \",i,\"=\",mean_values(i)\n",
    "    enddo    \n",
    "    \n",
    "    !$omp target exit data map(delete:table)\n",
    "    deallocate(table, mean_values)\n",
    "end program modular_programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8228011",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Using multiple GPUs with OpenMP\n",
    "\n",
    "If you have multiple accelerators available, you can select the one on which you run the kernels with the `device` clause of the `target` construct. It includes both `target data` constructs and `target teams/parallel` constructs.\n",
    "\n",
    "You should give an integer that refers to the gpu number (starting from 0) to the `device` clause, such as :\n",
    "\n",
    "```fortran\n",
    "    call mpi_comm_rank(MPI_COMM_WORLD,rank,code)\n",
    "    num_gpus = omp_get_num_devices()\n",
    "    my_gpu   = mod(my_rank,num_gpus)\n",
    "    !$omp target data map(...) device(my_gpu)\n",
    "        ...\n",
    "    !$omp end target data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6817ac76",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "\n",
    "In this exercise, you should bring on the gpu the MPI version of the generation of the Mandelbrot set on the gpu with OpenMP and by using multiple devices.\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_mandelbrot_mpi_exercise.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun  --cliopts \"2000 1000\" -m 4 -g 4 --options \"-mp=gpu -gpu=cc70 -Minfo=all\"\n",
    "program mandelbrot_mpi\n",
    "    use MPI\n",
    "    implicit none\n",
    "    real, parameter               :: min_re = -2.0, max_re = 1.0\n",
    "    real, parameter               :: min_im = -1.0, max_im = 1.0\n",
    "    integer                       :: first, last, width, height\n",
    "    integer                       :: num_elements\n",
    "    real                          :: step_w, step_h\n",
    "    integer                       :: numarg, i, length, j, first_elem,last_elem\n",
    "    integer                       :: rest_eucli,local_height\n",
    "    integer                       :: rank, nb_procs, code\n",
    "    character(len=:), allocatable :: arg1, arg2\n",
    "    integer (kind=1), allocatable :: picture(:)\n",
    "    real                          :: x, y\n",
    "\n",
    "    numarg = command_argument_count()\n",
    "    if (numarg .ne. 2) then\n",
    "        write(0,*) \"Error, you should provide 2 arguments of integer kind : width and length\"\n",
    "        stop\n",
    "    endif\n",
    "    call get_command_argument(1,LENGTH=length)\n",
    "    allocate(character(len=length) :: arg1)\n",
    "    call get_command_argument(1,VALUE=arg1)\n",
    "    read(arg1,'(i10)') width\n",
    "    call get_command_argument(2,LENGTH=length)\n",
    "    allocate(character(len=length) :: arg2)\n",
    "    call get_command_argument(2,VALUE=arg2)    \n",
    "    read(arg2,'(i10)') height\n",
    "    step_w = 1.0 / real(width)                                                    \n",
    "    step_h = 1.0 / real(height)\n",
    "\n",
    "    call mpi_init(code)\n",
    "    call mpi_comm_rank(MPI_COMM_WORLD,rank,code)\n",
    "    call mpi_comm_size(MPI_COMM_WORLD,nb_procs,code)\n",
    "\n",
    "    local_height = height / nb_procs\n",
    "    first = 0\n",
    "    last  = local_height\n",
    "    rest_eucli = mod(height,nb_procs)\n",
    "\n",
    "    if ((rank .eq. 0) .and. (rank .lt. rest_eucli)) last = last + 1\n",
    "\n",
    "    if (rank .gt. 0) then\n",
    "        do i = 1, rank\n",
    "            first = first + local_height\n",
    "            last  = last  + local_height\n",
    "                if (rank .lt. rest_eucli) then\n",
    "                    first = first + 1\n",
    "                    last  = last  + 1\n",
    "                endif\n",
    "        enddo\n",
    "    endif\n",
    "\n",
    "    if (rank .lt. rest_eucli) local_height = local_height + 1\n",
    "    num_elements = local_height * width\n",
    "\n",
    "    write(unit=*,fmt=\"(a9,i3,a18,i8,a3,i8,a5,i10,a9)\") \"I am rank\",rank, &\n",
    "    \" and my range is [\",first,\" ,\",last,\"[ ie \",num_elements,\" elements\"\n",
    "\n",
    "    allocate(picture(first*width:last*width))\n",
    "\n",
    "    do i=first,last-1\n",
    "        do j=0,width-1\n",
    "            x =  min_re + j * step_w * (max_re - min_re)\n",
    "            y =  min_im + i * step_h * (max_im - min_im)\n",
    "            picture(i*width+j) = mandelbrot_iterations(x,y)\n",
    "        enddo\n",
    "    enddo\n",
    "\n",
    "    call output()\n",
    "    deallocate(picture)\n",
    "\n",
    "    call mpi_finalize(code)\n",
    "\n",
    "    contains\n",
    "        subroutine output\n",
    "            integer                         :: fh\n",
    "            integer(kind=MPI_OFFSET_KIND)   :: woffset\n",
    "\n",
    "            woffset=first*width\n",
    "            call MPI_File_open(MPI_COMM_WORLD,\"mandel.gray\",MPI_MODE_WRONLY+MPI_MODE_CREATE,MPI_INFO_NULL,fh,code)\n",
    "            call MPI_File_write_at(fh,woffset,picture,num_elements,MPI_INTEGER1,MPI_STATUS_IGNORE,code);\n",
    "            call MPI_File_close(fh,code)\n",
    "        end subroutine output\n",
    "        integer(kind=1) function mandelbrot_iterations(x,y)\n",
    "            integer, parameter              :: max_iter = 127\n",
    "            real, intent(in)                :: x,y\n",
    "            real                            :: z1,z2,z1_old,z2_old\n",
    "\n",
    "            z1 = 0.0\n",
    "            z2 = 0.0\n",
    "            mandelbrot_iterations = 0\n",
    "            do while (((z1*z1+z2*z2) .le. 4) .and. (mandelbrot_iterations .lt. max_iter))\n",
    "                z1_old = z1\n",
    "                z2_old = z2\n",
    "                z1 = z1_old*z1_old - z2_old*z2_old  + x\n",
    "                z2 = 2.0*z1_old*z2_old + y\n",
    "                mandelbrot_iterations = mandelbrot_iterations + 1\n",
    "            enddo\n",
    "        end function mandelbrot_iterations      \n",
    "end program mandelbrot_mpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590753cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idrcomp import show_gray\n",
    "show_gray(\"mandel.gray\", 1000, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b297c9",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Solution\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_mandelbrot_mpi_solution.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f155cbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%idrrun  --cliopts \"2000 1000\" -m 4 -g 4 --options \"-mp=gpu -gpu=cc70 -Minfo=all\" \n",
    "program mandelbrot_mpi\n",
    "    use MPI\n",
    "    implicit none\n",
    "    real, parameter               :: min_re = -2.0, max_re = 1.0\n",
    "    real, parameter               :: min_im = -1.0, max_im = 1.0\n",
    "    integer                       :: first, last, width, height\n",
    "    integer                       :: num_elements\n",
    "    real                          :: step_w, step_h\n",
    "    integer                       :: numarg, i, length, j, first_elem,last_elem\n",
    "    integer                       :: rest_eucli,local_height\n",
    "    integer                       :: rank, nb_procs, code\n",
    "    character(len=:), allocatable :: arg1, arg2\n",
    "    integer (kind=1), allocatable :: picture(:)\n",
    "    real                          :: x, y\n",
    "\n",
    "    numarg = command_argument_count()\n",
    "    if (numarg .ne. 2) then\n",
    "        write(0,*) \"Error, you should provide 2 arguments of integer kind : width and length\"\n",
    "        stop\n",
    "    endif\n",
    "    call get_command_argument(1,LENGTH=length)\n",
    "    allocate(character(len=length) :: arg1)\n",
    "    call get_command_argument(1,VALUE=arg1)\n",
    "    read(arg1,'(i10)') width\n",
    "    call get_command_argument(2,LENGTH=length)\n",
    "    allocate(character(len=length) :: arg2)\n",
    "    call get_command_argument(2,VALUE=arg2)    \n",
    "    read(arg2,'(i10)') height\n",
    "    step_w = 1.0 / real(width)                                                    \n",
    "    step_h = 1.0 / real(height)\n",
    "\n",
    "    call mpi_init(code)\n",
    "    call mpi_comm_rank(MPI_COMM_WORLD,rank,code)\n",
    "    call mpi_comm_size(MPI_COMM_WORLD,nb_procs,code)\n",
    "\n",
    "    local_height = height / nb_procs\n",
    "    first = 0\n",
    "    last  = local_height\n",
    "    rest_eucli = mod(height,nb_procs)\n",
    "\n",
    "    if ((rank .eq. 0) .and. (rank .lt. rest_eucli)) last = last + 1\n",
    "\n",
    "    if (rank .gt. 0) then\n",
    "        do i = 1, rank\n",
    "            first = first + local_height\n",
    "            last  = last  + local_height\n",
    "                if (rank .lt. rest_eucli) then\n",
    "                    first = first + 1\n",
    "                    last  = last  + 1\n",
    "                endif\n",
    "        enddo\n",
    "    endif\n",
    "\n",
    "    if (rank .lt. rest_eucli) local_height = local_height + 1\n",
    "    num_elements = local_height * width\n",
    "\n",
    "    write(unit=*,fmt=\"(a9,i3,a18,i8,a3,i8,a5,i10,a9)\") \"I am rank\",rank, &\n",
    "    \" and my range is [\",first,\" ,\",last,\"[ ie \",num_elements,\" elements\"\n",
    "\n",
    "    allocate(picture(first*width:last*width))\n",
    "    !$omp target data map(tofrom:picture) device(rank)\n",
    "    !$omp target teams distribute parallel do simd collapse(2) device(rank)\n",
    "    do i=first,last-1\n",
    "        do j=0,width-1\n",
    "            x =  min_re + j * step_w * (max_re - min_re)\n",
    "            y =  min_im + i * step_h * (max_im - min_im)\n",
    "            picture(i*width+j) = mandelbrot_iterations(x,y)\n",
    "        enddo\n",
    "    enddo\n",
    "    !$omp end target data\n",
    "    call output()\n",
    "    deallocate(picture)\n",
    "\n",
    "    call mpi_finalize(code)\n",
    "\n",
    "    contains\n",
    "        subroutine output\n",
    "            integer                         :: fh\n",
    "            integer(kind=MPI_OFFSET_KIND)   :: woffset\n",
    "\n",
    "            woffset=first*width\n",
    "            call MPI_File_open(MPI_COMM_WORLD,\"mandel.gray\",MPI_MODE_WRONLY+MPI_MODE_CREATE,MPI_INFO_NULL,fh,code)\n",
    "            call MPI_File_write_at(fh,woffset,picture,num_elements,MPI_INTEGER1,MPI_STATUS_IGNORE,code);\n",
    "            call MPI_File_close(fh,code)\n",
    "        end subroutine output\n",
    "        integer(kind=1) function mandelbrot_iterations(x,y)\n",
    "            !$omp declare target\n",
    "            integer, parameter              :: max_iter = 127\n",
    "            real, intent(in)                :: x,y\n",
    "            real                            :: z1,z2,z1_old,z2_old\n",
    "\n",
    "            z1 = 0.0\n",
    "            z2 = 0.0\n",
    "            mandelbrot_iterations = 0\n",
    "            do while (((z1*z1+z2*z2) .le. 4) .and. (mandelbrot_iterations .lt. max_iter))\n",
    "                z1_old = z1\n",
    "                z2_old = z2\n",
    "                z1 = z1_old*z1_old - z2_old*z2_old  + x\n",
    "                z2 = 2.0*z1_old*z2_old + y\n",
    "                mandelbrot_iterations = mandelbrot_iterations + 1\n",
    "            enddo\n",
    "        end function mandelbrot_iterations      \n",
    "end program mandelbrot_mpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idrcomp import show_gray\n",
    "show_gray(\"mandel.gray\", 1000, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b7090",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Using NV-link with OpenMP target\n",
    "\n",
    "You can specify to the accelerator the pointer to a given data structure already present on the device that should be used with `use_device_addr` clause of the `data` construct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e102503",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "\n",
    "As an exercise, you can complete the following MPI code that measures the bandwidth between the GPUs:\n",
    "\n",
    "1. Add directives to create the buffers on the GPU\n",
    "2. Measure the effective bandwidth between GPUs by adding the directives necessary to transfer data from one GPU to another one in the following cases:\n",
    "\n",
    "- Not using NVLink\n",
    "- Using NVLink\n",
    "\n",
    "We have a bug for MPI in the notebooks and you need to save the file before running the next cell.\n",
    "It is a good way to pratice manual building!\n",
    "Please add the correct extension for the language you are running.\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_MultiGPU_mpi_exercise.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee26ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun  --cliopts \"2000 1000\" -m 4 -g 4 --options \"-mp=gpu -gpu=cc70 -Minfo=all\" \n",
    "! you should add ` --option \"-cpp\" ` as argument to the idrrun command\n",
    "program MultiGPU_exercice\n",
    "    use ISO_FORTRAN_ENV, only : INT32, REAL64\n",
    "    use mpi\n",
    "    use openacc\n",
    "    implicit none\n",
    "    real   (kind=REAL64), dimension(:), allocatable :: send_buffer, receive_buffer\n",
    "    real   (kind=REAL64)                            :: start, finish , data_volume   \n",
    "    integer(kind=INT32 ), parameter                 :: system_size = 2e8/8\n",
    "    integer                                         :: comm_size, my_rank, code, reps, i, j, k\n",
    "    integer                                         :: num_gpus, my_gpu\n",
    "    integer(kind=acc_device_kind)                   :: device_type\n",
    "    integer, dimension(MPI_STATUS_SIZE)             :: mpi_stat\n",
    "\n",
    "    ! Useful for OpenMPI and GPU DIRECT\n",
    "    call initialisation_openacc()\n",
    "\n",
    "    ! MPI stuff\n",
    "    reps = 5\n",
    "    data_volume = dble(reps*system_size)*8*1024_real64**(-3.0)\n",
    "\n",
    "    call MPI_Init(code)\n",
    "    call MPI_Comm_size(MPI_COMM_WORLD, comm_size, code)\n",
    "    call MPI_Comm_rank(MPI_COMM_WORLD, my_rank, code)\n",
    "    allocate(send_buffer(system_size), receive_buffer(system_size))\n",
    "\n",
    "    ! OpenACC stuff\n",
    "    #ifdef _OPENACC\n",
    "    device_type = acc_get_device_type()\n",
    "    num_gpus = acc_get_num_devices(device_type)\n",
    "    my_gpu   = mod(my_rank,num_gpus)\n",
    "    call acc_set_device_num(my_gpu, device_type)\n",
    "    #endif\n",
    "\n",
    "    do j = 0, comm_size - 1\n",
    "        do i = 0, comm_size - 1\n",
    "            if ( (my_rank .eq. j) .and. (j .ne. i) ) then\n",
    "                start = MPI_Wtime()\n",
    "                do k = 1, reps\n",
    "                    call MPI_Send(send_buffer,system_size, MPI_DOUBLE, i, 0, MPI_COMM_WORLD, code)\n",
    "                enddo\n",
    "            endif \n",
    "            if ( (my_rank .eq. i) .and. (i .ne. j) ) then\n",
    "                do k = 1, reps\n",
    "                    call MPI_Recv(receive_buffer, system_size, MPI_DOUBLE, j, 0, MPI_COMM_WORLD, mpi_stat, code)\n",
    "                enddo\n",
    "            endif\n",
    "            if ( (my_rank .eq. j) .and. (j .ne. i) ) then\n",
    "                finish = MPI_Wtime()\n",
    "                write(0,\"(a11,i2,a2,i2,a2,f20.8,a5)\") \"bandwidth \",j,\"->\",i,\": \",data_volume/(finish-start),\" GB/s\"\n",
    "            endif\n",
    "        enddo\n",
    "    enddo\n",
    "    \n",
    "    deallocate(send_buffer, receive_buffer)\n",
    "    \n",
    "    call MPI_Finalize(code)\n",
    "\n",
    "    contains\n",
    "        #ifdef _OPENACC\n",
    "        subroutine initialisation_openacc\n",
    "            use openacc\n",
    "            implicit none\n",
    "            type accel_info\n",
    "                integer :: current_devices\n",
    "                integer :: total_devices\n",
    "            end type accel_info\n",
    "\n",
    "            type(accel_info) :: info\n",
    "            character(len=6) :: local_rank_env\n",
    "            integer          :: local_rank_env_status, local_rank\n",
    "        ! Initialisation of OpenACC\n",
    "            !$acc init\n",
    "\n",
    "        ! Recovery of the local rank of the process via the environment variable\n",
    "        ! set by Slurm, as MPI_Comm_rank cannot be used here because this routine\n",
    "        ! is used BEFORE the initialisation of MPI\n",
    "            call get_environment_variable(name=\"SLURM_LOCALID\", value=local_rank_env, status=local_rank_env_status)\n",
    "            info%total_devices = acc_get_num_devices(acc_get_device_type())\n",
    "            if (local_rank_env_status == 0) then\n",
    "                read(local_rank_env, *) local_rank\n",
    "                ! Definition of the GPU to be used via OpenACC\n",
    "                call acc_set_device_num(local_rank, acc_get_device_type())\n",
    "                info%current_devices = local_rank\n",
    "            else\n",
    "                print *, \"Error : impossible to determine the local rank of the process\"\n",
    "                stop 1\n",
    "            endif\n",
    "        end subroutine initialisation_openacc\n",
    "        #endif \n",
    "\n",
    "end program MultiGPU_exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792186f7",
   "metadata": {
    "editable": false
   },
   "source": [
    "#### Solution\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_MultiGPU_mpi_solution.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b52563",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%idrrun  --cliopts \"2000 1000\" -m 4 -g 4 --options \"-mp=gpu -gpu=cc70 -Minfo=all\" \n",
    "! you should add ` --option \"-cpp\" ` as argument to the idrrun command\n",
    "program MultiGPU_solution\n",
    "    use ISO_FORTRAN_ENV, only : INT32, REAL64\n",
    "    use mpi\n",
    "    use openacc\n",
    "    implicit none\n",
    "    real   (kind=REAL64), dimension(:), allocatable :: send_buffer, receive_buffer\n",
    "    real   (kind=REAL64)                            :: start, finish , data_volume   \n",
    "    integer(kind=INT32 ), parameter                 :: system_size = 2e8/8\n",
    "    integer                                         :: comm_size, my_rank, code, reps, i, j, k\n",
    "    integer                                         :: num_gpus, my_gpu\n",
    "    integer(kind=acc_device_kind)                   :: device_type\n",
    "    integer, dimension(MPI_STATUS_SIZE)             :: mpi_stat\n",
    "\n",
    "    ! Useful for OpenMPI and GPU DIRECT\n",
    "    call initialisation_openacc()\n",
    "\n",
    "    ! MPI stuff\n",
    "    reps = 5\n",
    "    data_volume = dble(reps*system_size)*8*1024_real64**(-3.0)\n",
    "\n",
    "    call MPI_Init(code)\n",
    "    call MPI_Comm_size(MPI_COMM_WORLD, comm_size, code)\n",
    "    call MPI_Comm_rank(MPI_COMM_WORLD, my_rank, code)\n",
    "    allocate(send_buffer(system_size), receive_buffer(system_size))\n",
    "    !$omp target enter data map(alloc: send_buffer(1:system_size), receive_buffer(1:system_size))\n",
    "\n",
    "    ! OpenMP target stuff\n",
    "    #ifdef _OPENACC\n",
    "    device_type = acc_get_device_type()\n",
    "    num_gpus = acc_get_num_devices(device_type)\n",
    "    my_gpu   = mod(my_rank,num_gpus)\n",
    "    call acc_set_device_num(my_gpu, device_type)\n",
    "    #endif\n",
    "\n",
    "    do j = 0, comm_size - 1\n",
    "        do i = 0, comm_size - 1\n",
    "            if ( (my_rank .eq. j) .and. (j .ne. i) ) then\n",
    "                start = MPI_Wtime()\n",
    "                !$omp target data use_device_ptr(send_buffer)\n",
    "                do k = 1, reps\n",
    "                    call MPI_Send(send_buffer,system_size, MPI_DOUBLE, i, 0, MPI_COMM_WORLD, code)\n",
    "                enddo\n",
    "                !$omp end target data\n",
    "            endif \n",
    "            if ( (my_rank .eq. i) .and. (i .ne. j) ) then\n",
    "                !$omp target data use_device_ptr(send_buffer)\n",
    "                do k = 1, reps\n",
    "                    call MPI_Recv(receive_buffer, system_size, MPI_DOUBLE, j, 0, MPI_COMM_WORLD, mpi_stat, code)\n",
    "                enddo\n",
    "                !$omp end target data\n",
    "            endif\n",
    "            if ( (my_rank .eq. j) .and. (j .ne. i) ) then\n",
    "                finish = MPI_Wtime()\n",
    "                write(0,\"(a11,i2,a2,i2,a2,f20.8,a5)\") \"bandwidth \",j,\"->\",i,\": \",data_volume/(finish-start),\" GB/s\"\n",
    "            endif\n",
    "        enddo\n",
    "    enddo\n",
    "    !$omp target exit data map(delete: send_buffer, receive_buffer)\n",
    "    deallocate(send_buffer, receive_buffer)\n",
    "    \n",
    "    call MPI_Finalize(code)\n",
    "\n",
    "    contains\n",
    "        #ifdef _OPENACC\n",
    "        subroutine initialisation_openacc\n",
    "            use openacc\n",
    "            implicit none\n",
    "            type accel_info\n",
    "                integer :: current_devices\n",
    "                integer :: total_devices\n",
    "            end type accel_info\n",
    "\n",
    "            type(accel_info) :: info\n",
    "            character(len=6) :: local_rank_env\n",
    "            integer          :: local_rank_env_status, local_rank\n",
    "        ! Initialisation of OpenACC\n",
    "            !$acc init\n",
    "\n",
    "        ! Recovery of the local rank of the process via the environment variable\n",
    "        ! set by Slurm, as MPI_Comm_rank cannot be used here because this routine\n",
    "        ! is used BEFORE the initialisation of MPI\n",
    "            call get_environment_variable(name=\"SLURM_LOCALID\", value=local_rank_env, status=local_rank_env_status)\n",
    "            info%total_devices = acc_get_num_devices(acc_get_device_type())\n",
    "            if (local_rank_env_status == 0) then\n",
    "                read(local_rank_env, *) local_rank\n",
    "                ! Definition of the GPU to be used via OpenACC\n",
    "                call acc_set_device_num(local_rank, acc_get_device_type())\n",
    "                info%current_devices = local_rank\n",
    "            else\n",
    "                print *, \"Error : impossible to determine the local rank of the process\"\n",
    "                stop 1\n",
    "            endif\n",
    "        end subroutine initialisation_openacc\n",
    "        #endif \n",
    "\n",
    "end program MultiGPU_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ea6d8",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Asynchronism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47b531",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Concurrent executions within the same stream\n",
    "\n",
    "An implicit barrier is set at the end of each `target` construct to ensure that the parent task (the task on the host) can not move on until the target task has ended. You can disable this implicit behavior and submit several kernels on the GPU by explicitly adding the `nowait` clause to the target construct.\n",
    "\n",
    "In order to avoid race conditions that could arise from the lack of barrier between kernels, it is possible to specify a scheduling of the kernels based on a dependency mechanism. To do so, you should use the `depend` clause."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aad2c9",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_async_async_exercise.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728aa2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%idrrun --options \"-mp=gpu -gpu=cc70 -Minfo=all\"\n",
    "program prod_mat\n",
    "    use iso_fortran_env, only : INT32, REAL64\n",
    "    implicit none\n",
    "    integer (kind=INT32)               :: rank=5000\n",
    "    real    (kind=REAL64), allocatable :: A(:,:), B(:,:), C(:,:)\n",
    "    integer (kind=INT32)               :: i, j, k\n",
    "    integer (kind=INT32)               :: streamA, streamB, streamC\n",
    "\n",
    "    streamA = 1\n",
    "    streamB = 2\n",
    "    streamC = 3\n",
    "\n",
    "    call create_mat(A, rank, streamA)\n",
    "    call create_mat(B, rank, streamB)\n",
    "    call create_mat(C, rank, streamC)\n",
    "\n",
    "    call init_mat(A, rank, 3.0_real64 , streamA)\n",
    "    call init_mat(B, rank, 14.0_real64, streamB)\n",
    "    call init_mat(C, rank, 0.0_real64 , streamC)\n",
    "\n",
    "    do j=1, rank\n",
    "        do k=1, rank\n",
    "            do i=1, rank\n",
    "                C(i,j) = C(i,j) + A(i,k)*B(k,j)\n",
    "            enddo\n",
    "        enddo\n",
    "    enddo\n",
    "    print *, \"Check that this is close to 42.0:\", C(12,12)\n",
    "    deallocate(A, B, C)\n",
    "    contains\n",
    "        subroutine create_mat(mat, rank, stream)\n",
    "            real   (kind=REAL64), intent(inout), allocatable   :: mat(:,:)\n",
    "            integer(kind=INT32 ), intent(in)                   :: rank, stream\n",
    "            allocate(mat(rank,rank))\n",
    "        end subroutine create_mat\n",
    "\n",
    "        subroutine init_mat(mat, rank, diag, stream)\n",
    "            real    (kind=REAL64), intent(inout)   :: mat(:,:)\n",
    "            real    (kind=REAL64), intent(in)      :: diag\n",
    "            integer (kind=INT32 ), intent(in)      :: rank, stream\n",
    "            integer (kind=INT32 )                  :: i, j\n",
    "\n",
    "            do j=1, rank\n",
    "                do i=1, rank\n",
    "                   mat(i,j) = 0.0_real64\n",
    "                enddo\n",
    "            enddo\n",
    "\n",
    "            do j=1, rank\n",
    "                mat(j,j) = diag\n",
    "            enddo\n",
    "        end subroutine init_mat\n",
    "end program prod_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e2f44e",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Solution\n",
    "\n",
    "Example stored in: `../../examples/Fortran/OpenMP_async_async_solution.f90`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88935dc3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%idrrun --options \"-mp=gpu -gpu=cc70 -Minfo=all\"\n",
    "program prod_mat\n",
    "    use iso_fortran_env, only : INT32, REAL64\n",
    "    implicit none\n",
    "    integer (kind=INT32)               :: rank=5000\n",
    "    real    (kind=REAL64), allocatable :: A(:,:), B(:,:), C(:,:)\n",
    "    integer (kind=INT32)               :: i, j, k\n",
    "    integer (kind=INT32)               :: streamA, streamB, streamC\n",
    "\n",
    "    streamA = 1\n",
    "    streamB = 2\n",
    "    streamC = 3\n",
    "\n",
    "    call create_mat(A, rank, streamA)\n",
    "    call create_mat(B, rank, streamB)\n",
    "    call create_mat(C, rank, streamC)\n",
    "\n",
    "    call init_mat(A, rank, 3.0_real64 , streamA)\n",
    "    call init_mat(B, rank, 14.0_real64, streamB)\n",
    "    call init_mat(C, rank, 0.0_real64 , streamC)\n",
    "\n",
    "    !$omp target teams distribute parallel do simd collapse(3)\n",
    "    do j=1, rank\n",
    "        do k=1, rank\n",
    "            do i=1, rank\n",
    "                C(i,j) = C(i,j) + A(i,k)*B(k,j)\n",
    "            enddo\n",
    "        enddo\n",
    "    enddo\n",
    "    !$omp target exit data map(delete:A,B)\n",
    "    !$omp target exit data map(from:C)\n",
    "    print *, \"Check that this is close to 42.0:\", C(12,12)\n",
    "    deallocate(A, B, C)\n",
    "    contains\n",
    "        subroutine create_mat(mat, rank, stream)\n",
    "            real   (kind=REAL64), intent(inout), allocatable   :: mat(:,:)\n",
    "            integer(kind=INT32 ), intent(in)                   :: rank, stream\n",
    "            allocate(mat(rank,rank))\n",
    "            !$omp target enter data map(alloc:mat) nowait depend(out:mat)\n",
    "        end subroutine create_mat\n",
    "\n",
    "        subroutine init_mat(mat, rank, diag, stream)\n",
    "            real    (kind=REAL64), intent(inout)   :: mat(:,:)\n",
    "            real    (kind=REAL64), intent(in)      :: diag\n",
    "            integer (kind=INT32 ), intent(in)      :: rank, stream\n",
    "            integer (kind=INT32 )                  :: i, j\n",
    "\n",
    "            !$omp target teams distribute parallel do simd collapse(2) nowait depend(inout:mat)\n",
    "            do j=1, rank\n",
    "                do i=1, rank\n",
    "                   mat(i,j) = 0.0_real64\n",
    "                enddo\n",
    "            enddo\n",
    "\n",
    "            !$omp target teams distribute parallel do simd nowait depend(in:mat)\n",
    "            do j=1, rank\n",
    "                mat(j,j) = diag\n",
    "            enddo\n",
    "        end subroutine init_mat\n",
    "end program prod_mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU Directives",
   "language": "python",
   "name": "gpu_directives"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
